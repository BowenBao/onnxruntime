syntax = "proto2";

package LotusIR;

import "core/protobuf/Data.proto";
import "core/protobuf/Type.proto";
import "core/protobuf/TensorShape.proto";

// Note [Protobuf compatibility]
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// Based on experience working with downstream vendors, we generally can't
// assume recent versions of protobufs. This means that we do not use any
// protobuf features that are only available in proto3.

// Note [Namespaces]
// ~~~~~~~~~~~~~~~~~
// LotusIR gives explicit names to graphs, intermediate values and
// serialized tensors.  To make it easier to generate names, we organize
// these into separate namespaces (so, e.g., a graph can have the same
// name as a serialized tensor.)  The namespaces are as follows:
//
// - Node: These names identify specific nodes in the graph (but not,
//   necessarily any particular input or output of the node.
// - Graph: These names identify graphs in the protobuf.
// - Attribute: These names identify attribute names for extra attributes
//   that are passed to operators.
// - Operator and functions: These names identify particular operators and
//   functions.
// - Tensor: These names identify intermediate tensor values flowing through
//   the computation of a graph.
// - Shape: These names represent parameters for unknown shape dimensions.
//
// We specify the namespace of a name in LotusIR as comments in the form
// of "namespace {Node,Graph,Attribute,Tensor,Shape}". Framework is
// responsible for supporting the namespaces.

// Defines argument information set, except argument name.
// The argument could be an input or an output of a graph, node or function.
message ArgInfoProto {
  // This field MUST be present this version of the IR.  
    optional TypeProto type = 1;
  // This field MUST only be present if the type field is not a TensorTypeProto
    optional TensorShapeProto shape = 2;
}

// Defines a directed acyclic computation graph.
// All the input/output tensors are explicitly named so a framework can
// run any subgraph of the graph by feeding and fetching the named tensors.
message GraphProto {
//BUG:13806896,onnx: 
//          Format/protocol design 101. We need to put the version info
//          at the front of the format.  In the current layout, one has to 
//          parse past the entire graph + all initial tensor values prior
//          to knowing (a) if the IR_VERSION is supported and (b) whether
//          to quirk based on the producer_version/producer_tag.
//          The best layout would be:
//
//      ir_version
//      producer_version      
//      producer_tag
//      name
//      attributes
//      namespace
//      doc_string (can go anywhere before node and initializer)
//      input
//      output
//      node
//      initializer
//

  // The nodes in the graph.
  repeated NodeProto node = 1;

  // The name of the graph.
  optional string name = 2;   // namespace Graph

  // The inputs and outputs of the graph. The list input must be input names
  // of some nodes in the graph. The list output must be output names of some
  // nodes in the graph. For names in input that are not in initializer, their
  // types and shapes are required.
  //ISSUE:13807021,dbox: For input tensors that also appear in the initializer field,
  //            do we also expose those parameters as inputs to eval?
  repeated string input = 3;  // namespace Tensor
  repeated string output = 4; // namespace Tensor

  // An optional list of named initial values for tensors in the list of input above.
  // Used to pass serialized parameters for networks.
  // Each entry specifies a value for the input whose TensorProto.name matches
  // a name in the input. This list is a subset of input since many tensors
  // might not have initial values. 
  //ISSUE:13807021,onnx: Do we require at most one Tensor per input name? Given that
  //            our evaluation model allows multiple tensors to be fed into a 
  //            given node, I'm guessing we allow two or more tensors per
  //            input (and also allow users to provide it). I'll tighten up
  //            the text once we resolve. As written, it's ambiguous in ONNX.
  repeated TensorProto initializer = 5;

  // The version of the IR this graph targets. See Version enum below.
  // This field MUST be present this version of the IR.  
  optional int64 ir_version = 6;

  // The optional version of the framework runtime that generates this graph.
  // This producer_version has the same format as ir_version. 
  optional int64 producer_version = 7;

  // The optional name of the framework used to generate this graph in the form
  // "framework_name[-tag]". Tag is optional and provides additional
  // information such as `alpha` or `beta` or `rc3`.
  optional string producer_tag = 8;

//BUG:13806904,onnx: 
//          There is no `version` field.  Either fix the comment
//          or add a version field.  THis needs to get pushed back to ONNX
  // Domain of the graph.
  // We use reverse domain names as name space indicators. For example:
  // `com.facebook.fair` or `com.microsoft.cognitiveservices`
  //
  // Together with `name` and `version`, this forms the unique identity of
  // the graph.
  optional string domain = 9;

  // An optional human-readable documentation for this graph.
//ISSUE:13807035,onnx: In looking at FB's opschema stuff, they are definitely
//            using markdown syntax in their doc strings in that space.
//            Let's decide how we want to manage this.
  optional string doc_string = 10;

  // The function definitions of the graph. They can only only be used
  // (i.e., called) in this graph.
  // Each FunctionDefProto in function MUST have a unique name. 
  //ISSUE:13807045,dbox: Is the namespace of a function distinct from its peers and the graph?
  //ISSUE:13807045,dbox: Related - can a function body refer to GraphProto.initializer?
  repeated FunctionDefProto function = 11;

  // Argument information for input/output of this graph.
  // Each ArgInfoProto corresponds one-to-one by position with the 
  // input or output tensor of the graph.
  // The number of elements in input_arg_info MUST match the number 
  // of elements in the input field.
  // The number of elements in output_arg_info MUST match the number 
  // of elements in the output field.
  repeated ArgInfoProto input_arg_info = 12;
  repeated ArgInfoProto output_arg_info = 13;
  
  reserved 100 to 200; // for future extensions.
}

// To be compatible with both proto2 and proto3, we will use a version number
// that is not defined by the default value but an explicit enum number.
enum Version {
  // The version field is always serialized and we will use it to store the
  // version that the  graph is generated from. This helps us set up version
  // control. We should use version as
  //     xx(major) - xx(minor) - xxxx(bugfix)
  // and we are starting with 00000001.
  IR_VERSION = 00000001;
}

// Defines a node in a computation graph. Each graph node is either an
// operator or a function call.
//
// NOTE: Control flow is defined by two built-in operators:
//
// Cond(p, true_input, false_input) takes three inputs, where p is a
// boolean scalar tensor, true_input is the list of inputs to the true
// branch of cond, and false_input is the list of inputs to the false
// branch of cond. The true and false branches are defined as 
// functions that takes true_input and false_input as inputs respectively.
// The two functions must have the same number of outputs, and each
// corresponding output must have the same types, and have compatible
// shapes.
//
// While(vars, consts) takes two inputs, where vars are the initial
// values of the loop variables and consts are the values of constants
// used inside the loop. The loop condition and loop body are defined
// as functions. The functions take both vars and consts as inputs.
// The loop condition function returns a boolean scalar tensor. The
// loop body function has the form: body(vars, consts) = new_vars,
// where new_vars are the new values of the loop variables after one
// iteration so must match vars in terms of types and shapes.
message NodeProto {

  // The named inputs of the node.
  repeated string input = 1;   // namespace Tensor

  // The named outputs of the node.
  repeated string output = 2;  // namespace Tensor

  // The name of this node.
  // This field is optional and used to uniquely identify nodes in the graph.
  optional string name = 3;    // namespace Node

  // The name of the operator/function called by the node.
  // This field MUST be present for this version of the IR.
  optional string op_type = 4; // namespace Operator

  // Additional named attributes.
  repeated AttributeProto attribute = 5;

  // An optional human-readable documentation for this node in the graph.
  optional string doc_string = 6;

  // Information including type and shape for each input and output
  // argument of the operator/function called by the node.
  //ISSUE:13806939,dbox: Mail thread pending on type inferencing model. 
  repeated ArgInfoProto input_arg_info = 7;
  repeated ArgInfoProto output_arg_info = 8;

  // The number of inputs for each argument of the operator/function.
  // A formal parameter of the op may take a variable number of inputs
  // that is only known when this node is constructed.
  //BUG:13806939,dbox: I'm assuming that this field is like input_arg_info in that
  //          a zero element/missing array implies that one needs to crawl
  //          the graph to figure out the input counts, yes? COnfirm and I'll
  //          make clear.  Otherwise, we need to require it to be present
  //          and accurate.
  repeated int32 input_arg_count = 9;

  // Specify a list of named nodes that must be executed before this node.
  // Framework may use this to give users the ability to impose additional
  // execution orders for the operations.
  repeated string control_input = 10;
}

// Defines a function.
// A function is well-formed if
//   - input_arg.name is the name of an InParam node in `node`.
//   - output_arg.name is the name of an OutParam node in `node`.
message FunctionDefProto {
  message FunctionParam {
    optional string name = 1;
    optional TypeProto type = 2;
    optional TensorShapeProto shape = 3;
  //ISSUE:13807069,dbox: Resolving attribute locations offline.
  };

  // The name of the function.
  // This field MUST be present for this version of the IR.
  optional string name = 1;

  // The input parameters of the function.
  repeated FunctionParam input_arg = 2;

  // The output parameters of the function.
  repeated FunctionParam output_arg = 3;

  // The body of the function.
  repeated NodeProto node = 4;

  // The named attributes of the function.
  repeated AttributeProto attr = 5;
}

//BUG:13806952,onnx: Make clear that name is required. The ONNX spec uses "should"
// A named attribute containing either singular float, integer, string
// and tensor values, or repeated float, integer, string and tensor values.
// An AttributeProto MUST contain the name field, and *only one* of the
// following content fields, effectively enforcing a C/C++ union equivalent.
message AttributeProto {
  // This field MUST be present for this version of the IR.
  optional string name = 1;           // namespace Attribute
  optional float f = 2;               // float
  optional int64 i = 3;               // int
  optional bytes s = 4;               // UTF-8 string
  optional TensorProto t = 5;         // tensor value
  optional GraphProto g = 6;          // graph

  repeated float floats = 7;          // list of floats 
  repeated int64 ints = 8;            // list of ints
  repeated bytes strings = 9;         // list of UTF-8 strings
  repeated TensorProto tensors = 10;  // list of tensors
  repeated GraphProto graphs = 11;    // list of graph

  optional TypeProto type = 12;
  repeated TypeProto types = 13;
  //ISSUE:13807134,dbox: Do we ever see shape showing up as an attribute value?
  //            If so, won't it always be accompanied by a TypeProto?
  optional TensorShapeProto shape = 14;
  repeated TensorShapeProto shapes = 15;
}
